\chapter{Zusammenfassung}
\label{zusammenfassung}

Entscheidungsbäume bieten diverse Vorteile gegenüber anderen Methoden. Einer der offensichtlichsten Vorteile ist die einfache Verständlichkeit und Interpretierbarkeit von Entscheidungsbäumen. \autocite{DataMining} Sie können visualisiert werden und ermöglichen es somit auch Laien mit ihnen zu Arbeiten. \autocite{PythonCourseDecisionTrees:online} Außerdem können Entscheidungsbäume aus Datensätzen erstellt werden die nicht normalisiert sind und sowohl numerische als auch mit kategoriale Attribute enthalten. Dabei können Entscheidungsbäume auch mit sehr großen Datensätzen arbeiten. \autocite{PythonCourseDecisionTrees:online}\\

Aber natürlich besitzen Entscheidungsbäume auch Einschränkungen. So sind sie sind relativ inkonsistent, da bereits kleine Änderungen innerhalb des Trainingsdatensatzes zu weitreichenden Veränderungen des Entscheidungsbaums führen können. \autocite{PythonCourseDecisionTrees:online}\\
Besonders bei Entscheidungsbäumen kann es zu Overfitting kommen wodurch reale Daten falsch klassifiziert werden. Allerdings kann diesem Problem mittels Pruning entgegengewirkt werden. \autocite{DataMining}\\
Wenn Datensätze verwendet werden, die kategorialen Attribute mit einer Vielzahl von möglichen Ausprägungen besitzen, ist der Informationsgewinn in Entscheidungsbäumen zugunsten dieser Attribute ausgelegt.\autocite{PythonCourseDecisionTrees:online}