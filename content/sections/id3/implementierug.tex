\section{Implementation}
\label{id3:implementation}

Diese persönliche Implementation besteht im wesentlichen aus vier Funktionen. Zum einen aus Nebenfunktionen wie der Berechnung des Informationsgewinns, der Entropie und des Modalwerts, zum anderen aus der Hauptfunktion bzw. dem eigentlichen ID3 Algorithmus.

\subsection{Berechnung der Entropie}
\label{id3:implementation-entropie}
Die hier vorliegende Implementation zur Berechnung der Entropie erwartet als Eingabeparameter ein Attribut eines Datensatzes. Im Anschluss daran wird über die Zuweisung in Zeile 3 die Anzahl aller Ausprägungne des Attributes ermittelt. Dabei kommt die Bibliotheksfunktion \mintinline{python}{np.unique} zum Einsatz. Diese Funktion gibt zwei Listen zurück. Die erste Liste beinhaltet dabei alle möglichen Ausprägungen des Attributes während die zweite Liste die Anzahl eben jener Ausprägungen beinhaltet. Im Anschluss daran wird über die Länge der Liste \mintinline{python}{count} iteriert. Dabei wird in jedem Durchlauf die Wahrscheinlichkeit einer Ausprägung des Attributes berechnet. Außerdem wird die Entropie partiell für die vorliegende Ausprägung berechnet und mit dem vorherigen partiellen Entropiewert addiert.

\begin{figure}[H]
    \vspace{0.5cm}
    \centering
    \begin{minted}[linenos, breaklines, fontsize=\small]{python}
        def entropy(attribute):
            entropy = 0.0
            values, count = np.unique(attribute, return_counts=True)
            for index in range(len(values)):
                probablility = count[index] / sum(count)
                entropy += (-probablility * np.log2(probablility))
            return entropy
    \end{minted}
    \caption{Funktion zu Berechnung der Entropie eines Attributes\autocites{PythonCourseDecisionTrees:online}{ImplementationID3}}
\end{figure}

\subsection{Berechnung des Informationsgewinns}
\label{id3:implementation-ig}
Die vorliegende Implementation des Informationsgewinns erwartet drei Eingabeparameter. Diese sind der Datensatz, ein Attribut dieses Datensatzes und das Zielattribute gegen welches der Informationsgewinns bestimmt werden soll. Zu Beginn werden unter Zu­hil­fe­nah­me der Funktion \mintinline{python}{np.unique} alle möglichen Ausprägungen des Attributes sowie deren Anzahl bestimmt.\\
Im Hauptteil dieser Funktion wird über die möglichen Ausprägungen \mintinline{python}{values} des Attribute iteriert. Dabei wird in Zeile 5 zunächst eine Teilmenge \mintinline{python}{subdata} des ursprünglichen Datensatzes gebildet (vgl. Kapitel \ref{id3:gain}). Im Anschluss daran wird die Wahrscheinlichkeit der Ausprägung \mintinline{python}{value}, sowie die Entropie der Teilmenge \mintinline{python}{subdata} berechnet. Dabei werden die Entropieen der verschiedenen Ausprägungen addiert. Im letzen Schritt wird der Informationsgewinn aus der Differenz der Entropie des Zielattributes und der bedingten Entropie berechnet (vgl. Kapitel \ref{id3:gain}).

\begin{figure}[H]
    \centering
    \begin{minted}[linenos, breaklines, fontsize=\small]{python}
        def information_gain(data, attribute, target_attribute):
            values, count = np.unique(data[attribute], return_counts=True)
            entropy_val = 0.0
            for index, value in enumerate(values):
                subdata = data[data[attribute] == value][target_attribute]
                probablility = count[index] / sum(count)
                entropy_val += ( probablility * entropy(subdata) )
            target_entropy = entropy(data[target_attribute])
            information_gain = target_entropy - entropy_val
            return information_gain
    \end{minted}
    \caption{Funktion zur Berechnung des Informationsgewinns \autocites{PythonCourseDecisionTrees:online}{ImplementationID3}}
\end{figure}

\subsection{Berechnung des Modalwertes}
\label{id3:implementation-modal}
Die Funktion \mintinline{python}{modal} erwartet eine Liste von Elementen als Eingabeparameter. Zu Beginn der Funktion wird zunächst mit Hilfe der Funktion \mintinline{python}{np.unique} die Menge aller vorkommenden Werte sowie deren Anzahl in der Anfangsliste bestimmt. Im Anschluss daran wird aus beiden Informationen ein Dictionary erstellt. Im letzten Schritt wird mittels einer Lambda Funktion der Schlüssel des Dictionary ermittelt dessen Wert am höchsten ist.

\begin{figure}[H]
    \centering
    \begin{minted}[linenos, breaklines, fontsize=\small]{python}
        def modal(attribute):
            values, count = np.unique(attribute, return_counts=True)
            total = dict(zip(values, count))
            return max(total, key=lambda k: total[k])
    \end{minted}
    \caption{Berechnung des Modalwertes \autocite{MaxKeyByValue:online}}
\end{figure}

\subsection{ID3 - Hauptfunktion}
\label{id3:implementation-id3}
Die Hauptfunktion erwartet als Eingabeparameter den Ursprungsdatensatz, das Zielattribut und eine Liste aller möglichen Attribute des Datensatzes. Bei dem Zielattribut handelt es sich um die Klassifizierung.\\
Zu Beginn der Funktion werden zwei Abbruchbedingungen geprüft (vgl. Kapitel \ref{id3:funktionsweise}). Als erstes wird untersucht, ob die sich in dem Datensatz \mintinline{python}{data_set} auschließlich Objekte mit der gleichen Klassifizierung befinden. Wenn dem so ist, wird genau diese Klassifizierung zurück gegeben. Als zweites wird untersucht, ob bereits alle Attribute verwendet worden sind. Sofern dies zutrifft wird der Modalwert des Zielattributes zurück gegeben.\\
Im Anschluss daran wird mit der Funktion \mintinline{python}{calculate_all_IG} der Informationsgewinn für jedes Attribut berechnet, wobei das Attribut mit dem höchsten Wert (\mintinline{python}{best_attribute}) als (Wurzel-) Knoten gewählt wird. Im Anschluss daran wird in Zeile 10 \mintinline{python}{best_attribute} aus der Menge aller Attribute entfernt.\\
Nun beginnt der iterative Teil der Funktion. Dabei wird über alle Ausprägungen des Attributes \mintinline{python}{best_attribute} eine Teilmenge \mintinline{python}{subset} des ursprünglichen Datensatzes erstellt. Danach wird die dritte Abbruchbedingung für die Rekursion geprüft, nämlich ab die Teilmenge \mintinline{python}{subset} leer ist. In diesem Fall wird ein Blatt erstellt welchem der Modalwert \mintinline{python}{modal_value} des Zielattributes zugeordnet wird. Wenn allerdings die Teilmenge \mintinline{python}{subset} nicht leer ist, so wird in Zeile 18 rekursiv ein Teilbaum erstellt. Dieser wird in Zeile 19 der Ausprägung \mintinline{python}{value} des Attributes \mintinline{python}{best_attribute} zugewiesen.

\begin{figure}[H]
    \centering
    \begin{minted}[linenos, breaklines, fontsize=\small]{python}
        def ID3(data_set, target_attribute, attributes):
            if len(np.unique(data_set[target_attribute])) <= 1:
                return np.unique(data_set[target_attribute])[0]
            if len(attributes) <= 1:       
                return modal(data_set[target_attribute])

            IG = calculate_all_IG(data_set, target_attribute, attributes)
            best_attribute = max(IG, key=lambda k: IG[k])
            tree = {best_attribute: {}}
            attributes = [x for x in attributes if x != best_attribute]

            for value in np.unique(data_set[best_attribute]):
                subset = data_set[data_set[best_attribute] == value]
                if subset.empty:
                    modal_value = modal(data_set[target_attribute])
                    tree[best_attribute][value] = modal_value
                else:
                    subtree = ID3(subset, target_attribute, attributes)
                    tree[best_attribute][value] = subtree
            return tree
    \end{minted}
    \caption{Hauptfunktion des ID3 Algorithmus \autocites{MaxKeyByValue:online}{ID3algor15:online}{PythonCourseDecisionTrees:online}}
\end{figure}